{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import BertTokenizer\nimport torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom transformers import BertModel, BertConfig\nfrom tqdm import tqdm\n\n#Import model for evaluation\nmodel = torch.load('ROUTE TO MODEL')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model evaluation function\ndef evaluate(model, test_data):\n\n    test = Dataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n\n        model = model.cuda()\n\n    total_acc_test = 0\n    with torch.no_grad():\n\n        for test_input, test_label in test_dataloader:\n\n              test_label = test_label.to(device)\n              mask = test_input['attention_mask'].to(device)\n              input_id = test_input['input_ids'].squeeze(1).to(device)\n\n              output = model(input_id, mask)\n\n              acc = (output.argmax(dim=1) == test_label).sum().item()\n              total_acc_test += acc\n    \n    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Model prediction function\ndef predict(model, test_data):\n\n    test = PredictDataset(test_data)\n\n    dataloader = torch.utils.data.DataLoader(test, batch_size=1)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n    \n    outputs = []\n    with torch.no_grad():\n        for test_input in dataloader:\n              mask = test_input['attention_mask'].to(device)\n              input_id = test_input['input_ids'].squeeze(1).to(device)\n\n              output = model(input_id, mask)\n              label = id2label[output.argmax(dim=1).item()]\n              outputs.append(label)\n    return outputs","metadata":{},"execution_count":null,"outputs":[]}]}